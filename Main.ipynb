{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import *\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "df=pd.read_excel(\"Input/Input.xlsx\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\" #using a pretrained model \n",
    "\n",
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "#This is used to Calculate the Average postive negative and neutrality score\n",
    "def ScoreCalculator(FileName):\n",
    "\n",
    "    f=open(FileName, 'r')\n",
    "    NegativeScore=0    \n",
    "    PositiveScore=0\n",
    "    NeutralScore=0\n",
    "    number=0\n",
    "    StringWord=[]\n",
    "    ExceptionEncountered=False\n",
    "    Scores_exp=[0,0,0]\n",
    "\n",
    "    for line in f:\n",
    "        number+=1\n",
    "        try:\n",
    "            encoded_text = tokenizer(line, return_tensors='pt')\n",
    "            output = model(**encoded_text)\n",
    "            scores = output[0][0].detach().numpy()\n",
    "            scores = softmax(scores)\n",
    "            NegativeScore=NegativeScore+scores[0]\n",
    "            NeutralScore=NeutralScore+scores[1]\n",
    "            PositiveScore=PositiveScore+scores[2]\n",
    "        except:\n",
    "            StringWord.append(line)\n",
    "            ExceptionEncountered=True\n",
    "            \n",
    "\n",
    "    if(ExceptionEncountered):\n",
    "        Scores_exp=ExceptionHandler(StringWord)       \n",
    "        Average_dict = {\n",
    "            'roberta_NegativeScore' : (NegativeScore+Scores_exp[\"NegativeScore\"])/(number+1),\n",
    "            'roberta_NeutralScore' : (NeutralScore+Scores_exp[\"NeutralScore\"])/(number+1),\n",
    "            'roberta_PositiveScore' : (PositiveScore+Scores_exp[\"PositiveScore\"])/(number+1)\n",
    "        }\n",
    "    else:\n",
    "         Average_dict = {\n",
    "            'roberta_NegativeScore' : NegativeScore/number,\n",
    "            'roberta_NeutralScore' : NeutralScore/number,\n",
    "            'roberta_PositiveScore' : NeutralScore/number,\n",
    "        }       \n",
    "    \n",
    "    return(NegativeScore/number,NeutralScore/number,NeutralScore/number,)\n",
    "\n",
    "#This function is used to handle the Exception thrown by the Model as the model does not support tensor larger than 520\n",
    "def ExceptionHandler(String):\n",
    "    NegativeScore=0    \n",
    "    PositiveScore=0\n",
    "    NeutralScore=0\n",
    "    StringNeed=[]\n",
    "    StringProcess=\"\"\n",
    "    itr=0\n",
    "    length=len(String)\n",
    "    TotalNeu=0\n",
    "    TotalNeg=0\n",
    "    TotalPost=0\n",
    "    for StringItem in String:\n",
    "        number =0\n",
    "        StringNeed=StringItem.split()\n",
    "        for item in StringNeed:\n",
    "            if(number%25==0 and number !=0):\n",
    "                scores=ModelOuput(StringProcess)\n",
    "                StringProcess=\"\"\n",
    "                NegativeScore=NegativeScore+scores[0]\n",
    "                NeutralScore=NeutralScore+scores[1]\n",
    "                PositiveScore=PositiveScore+scores[2]\n",
    "            else:\n",
    "                StringProcess=StringProcess+\" \"+item\n",
    "            number+=1\n",
    "        TotalPost=(PositiveScore/number)+TotalPost\n",
    "        TotalNeg=(NegativeScore/number)+TotalNeg\n",
    "        TotalNeu=(NeutralScore/number)+TotalNeu\n",
    "\n",
    "\n",
    "    Average_local = {\n",
    "        'NegativeScore' : TotalNeg/length,\n",
    "        'NeutralScore' : TotalNeu/length,\n",
    "        'PositiveScore' : TotalPost/length\n",
    "    }\n",
    "\n",
    "\n",
    "    return(Average_local)\n",
    "\n",
    "\n",
    "def ModelOuput(String):\n",
    "\n",
    "    encoded_text = tokenizer(String, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    return(scores)\n",
    "\n",
    "\n",
    "def PolarityCal(TotalWords,Neg,Positive):\n",
    "\n",
    "    PolarityScore=((Positive-Neg)/(Positive+Neg))+0.000001\n",
    "\n",
    "    Subjectivity=((Positive+Neg)/TotalWords)+ 0.000001\n",
    "\n",
    "    return(PolarityScore,Subjectivity)\n",
    "\n",
    "def CountWords(filename):\n",
    "    NoComplex=0\n",
    "    NoSyllabus=0\n",
    "    WordCount=0\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()\n",
    "        TotalWords = len(words)\n",
    "        for itere in range(TotalWords):\n",
    "            if(ComplexWord(words[itere])):\n",
    "                NoComplex+=1  \n",
    "            NoSyllabus=NoSyllabus+syllabus(ps.stem(words[itere]))\n",
    "             \n",
    "    return (TotalWords,NoComplex,NoSyllabus)\n",
    "\n",
    "def ComplexWord(words):\n",
    "    count=0\n",
    "    for char in range(len(words)):\n",
    "            if (words[char] == 'a' or words[char] == 'e' or words[char] == 'i' or words[char] == 'o' or words[char] == 'u' or words[char] == 'A' or words[char] == 'E' or words[char] == 'I' or words[char] == 'O' or words[char] == 'U'):\n",
    "                count+=1\n",
    "    if(count>=2):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)   \n",
    "    \n",
    "def Sentence(FileName):\n",
    "    num_lines=0\n",
    "    number=0\n",
    "    with open(FileName,'r') as file:\n",
    "        for line in file:\n",
    "            number+=1\n",
    "            num_lines += line.count(\".\")\n",
    "            num_lines += line.count(\"?\")\n",
    "            num_lines += line.count(\":-\")\n",
    "    return(num_lines)\n",
    "\n",
    "def syllabus(word):\n",
    "    count=0\n",
    "    for char in range(len(word)):\n",
    "            if (word[char] == 'a' or word[char] == 'e' or word[char] == 'i' or word[char] == 'o' or word[char] == 'u' or word[char] == 'A' or word[char] == 'E' or word[char] == 'I' or word[char] == 'O' or word[char] == 'U'):\n",
    "                count+=1\n",
    "    return(count)\n",
    "\n",
    "def pronouns(FileName):\n",
    "    pronouns=0\n",
    "    pro = re.compile(r'\\b(I|he|she|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    with open(FileName,'r') as file:\n",
    "        for line in file:\n",
    "            pronouns = pronouns+len(pro.findall(line))\n",
    "    return(pronouns)\n",
    "\n",
    "def WordLen(FileName):\n",
    "    count=0\n",
    "    with open(FileName,'r') as file:\n",
    "        content = file.read()\n",
    "        word = content.split()\n",
    "        TotalWords = len(word)\n",
    "        for itere in range(TotalWords):\n",
    "            WordChar=word[itere]\n",
    "            for char in range(len(WordChar)):\n",
    "                count+=1\n",
    "        count=count/TotalWords\n",
    "    return(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemovalText(RemovalFile):\n",
    "    #open the text file  \n",
    "    with open('removal.txt', 'r') as f: \n",
    "        #read the text file into a list of lines \n",
    "        lines = f.readlines() \n",
    "        \n",
    "    #create an empty dictionary \n",
    "    file_dict = []\n",
    "        \n",
    "        #loop through the lines in the text file  \n",
    "    for line in lines: \n",
    "        line=line.replace(\"\\n\",\"\")\n",
    "        file_dict.append(line)\n",
    "\n",
    "    FileDict=file_dict\n",
    "\n",
    "    return(file_dict)\n",
    "\n",
    "\n",
    "file_dict= RemovalText('Input/removal.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DataExtration(URL_ID,UrlAddress,file_dict):\n",
    "\n",
    "    #Setting the max number of seconds to allow for processing\n",
    "    timeout = 10\n",
    "\n",
    "    #This function is used to extract the data from the articles\n",
    "\n",
    "    URL_str=os.path.join(\"ArticleData/\",str(URL_ID))\n",
    "    URL_str=str(URL_str)+\".txt\"\n",
    "    try:\n",
    "        # urllib.request.urlretrieve(UrlAddress,\"HtmlTemp.txt\")\n",
    "        response = requests.get(UrlAddress,timeout=timeout).text\n",
    "    except:\n",
    "        print(\"Error 404 \"+UrlAddress)\n",
    "\n",
    "    # file = open(\"HtmlTemp.txt\", \"r\")\n",
    "    # contents = file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    title = soup.title.string\n",
    "\n",
    "    f = open(URL_str, \"w\")\n",
    "\n",
    "    f.writelines(title+\"\\n\")\n",
    "\n",
    "    for data in soup.find_all(\"p\"):\n",
    "        sum = data.get_text()\n",
    "\n",
    "        #Removal of unwanted data\n",
    "        for element in file_dict:\n",
    "            if sum == element:\n",
    "                IsTrue=True\n",
    "                break\n",
    "            else:\n",
    "                IsTrue=False\n",
    "\n",
    "        if IsTrue:\n",
    "            continue\n",
    "        else:\n",
    "            f.writelines(sum+\"\\n\")\n",
    "\n",
    "    for data in soup.find_all(\"ol\"):\n",
    "        sum = data.get_text()\n",
    "\n",
    "        #Removal of unwanted data\n",
    "        for element in file_dict:\n",
    "            if sum == element:\n",
    "                IsTrue=True\n",
    "                break\n",
    "            else:\n",
    "                IsTrue=False\n",
    "\n",
    "        if IsTrue:\n",
    "            continue\n",
    "        else:\n",
    "            f.writelines(sum+\"\\n\")\n",
    " \n",
    "    f.close()\n",
    "\n",
    "    return(URL_str)\n",
    "\n",
    "\n",
    "def StopWordRemoval(NameFile,Url):\n",
    "\n",
    "    String=\"\"\n",
    "    Url=os.path.join(\"ArticleData/ProcessedData/\",str(Url)+\".txt\")\n",
    "    f=open(Url,\"w\")\n",
    "    file = open(NameFile,\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        String=\"\"\n",
    "        doc=nlp(line)\n",
    "        for token in doc:\n",
    "            if not token.is_stop and not token.is_punct:\n",
    "                String=String+\" \"+str(token)\n",
    "        f.writelines(String+\"\\n\")\n",
    "\n",
    "\n",
    "    return(Url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticleData/1.txt\n",
      "ArticleData/2.txt\n",
      "ArticleData/3.txt\n",
      "ArticleData/4.txt\n",
      "ArticleData/5.txt\n",
      "ArticleData/6.txt\n",
      "ArticleData/7.txt\n",
      "ArticleData/8.txt\n",
      "ArticleData/9.txt\n",
      "ArticleData/10.txt\n",
      "ArticleData/11.txt\n",
      "Error 404 https://dl.acm.org/doi/pdf/10.1145/2843948\n",
      "ArticleData/13.txt\n",
      "ArticleData/14.txt\n",
      "ArticleData/15.txt\n",
      "ArticleData/16.txt\n",
      "ArticleData/17.txt\n",
      "ArticleData/18.txt\n",
      "ArticleData/19.txt\n",
      "ArticleData/20.txt\n",
      "ArticleData/21.txt\n",
      "ArticleData/22.txt\n",
      "ArticleData/23.txt\n",
      "ArticleData/24.txt\n",
      "Error 404 https://www.investopedia.com/netflix-looks-to-accelerate-revenue-and-subscriber-growth-for-q4-8546779\n",
      "Error 404 https://www.investopedia.com/netflix-looks-to-accelerate-revenue-and-subscriber-growth-for-q4-8546779\n",
      "ArticleData/26.txt\n",
      "Error 404 https://www.investopedia.com/netflix-s-better-than-expected-q4-revenue-got-a-boost-from-strong-subscriber-growth-8547829\n",
      "ArticleData/28.txt\n",
      "ArticleData/29.txt\n",
      "ArticleData/30.txt\n",
      "ArticleData/31.txt\n",
      "ArticleData/32.txt\n",
      "ArticleData/33.txt\n",
      "ArticleData/34.txt\n",
      "ArticleData/35.txt\n",
      "ArticleData/36.txt\n",
      "ArticleData/37.txt\n",
      "ArticleData/38.txt\n",
      "ArticleData/39.txt\n",
      "ArticleData/40.txt\n",
      "ArticleData/41.txt\n",
      "ArticleData/42.txt\n",
      "ArticleData/43.txt\n",
      "ArticleData/44.txt\n",
      "ArticleData/45.txt\n",
      "ArticleData/46.txt\n",
      "ArticleData/47.txt\n",
      "ArticleData/48.txt\n",
      "Error 404 https://aaronhall.com/insights/reshaping-movie-culture-netflixs-impact-on-availability-and-cultural-references/\n",
      "ArticleData/50.txt\n",
      "ArticleData/51.txt\n",
      "ArticleData/52.txt\n",
      "ArticleData/53.txt\n",
      "Error 404 https://www.investopedia.com/is-amazon-prime-worth-it-5081871\n",
      "ArticleData/55.txt\n",
      "ArticleData/56.txt\n",
      "ArticleData/57.txt\n",
      "ArticleData/58.txt\n",
      "ArticleData/59.txt\n",
      "ArticleData/60.txt\n",
      "ArticleData/61.txt\n",
      "ArticleData/62.txt\n",
      "ArticleData/63.txt\n",
      "ArticleData/64.txt\n",
      "ArticleData/65.txt\n",
      "Error 404 https://www.androidpolice.com/amazon-prime-guide/\n",
      "Error 404 https://www.androidpolice.com/amazon-prime-guide/\n",
      "ArticleData/67.txt\n",
      "ArticleData/68.txt\n",
      "ArticleData/69.txt\n",
      "ArticleData/70.txt\n",
      "ArticleData/71.txt\n",
      "ArticleData/72.txt\n",
      "Error 404 https://money.usnews.com/money/personal-finance/saving-and-budgeting/articles/what-to-know-about-amazon-prime\n",
      "Error 404 https://money.usnews.com/money/personal-finance/saving-and-budgeting/articles/what-to-know-about-amazon-prime\n",
      "ArticleData/74.txt\n",
      "ArticleData/75.txt\n",
      "ArticleData/76.txt\n",
      "ArticleData/77.txt\n",
      "ArticleData/78.txt\n",
      "ArticleData/79.txt\n",
      "ArticleData/80.txt\n",
      "ArticleData/81.txt\n",
      "ArticleData/82.txt\n",
      "ArticleData/83.txt\n",
      "ArticleData/84.txt\n",
      "ArticleData/85.txt\n",
      "ArticleData/86.txt\n",
      "ArticleData/87.txt\n",
      "ArticleData/88.txt\n",
      "ArticleData/89.txt\n",
      "ArticleData/90.txt\n",
      "ArticleData/91.txt\n",
      "ArticleData/92.txt\n",
      "ArticleData/93.txt\n",
      "ArticleData/94.txt\n",
      "ArticleData/95.txt\n",
      "ArticleData/96.txt\n",
      "ArticleData/97.txt\n",
      "ArticleData/98.txt\n",
      "ArticleData/99.txt\n",
      "ArticleData/100.txt\n",
      "ArticleData/101.txt\n",
      "ArticleData/102.txt\n",
      "ArticleData/103.txt\n",
      "ArticleData/104.txt\n",
      "ArticleData/105.txt\n",
      "ArticleData/106.txt\n",
      "ArticleData/107.txt\n",
      "ArticleData/108.txt\n",
      "Error 404 https://www.hindustantimes.com/business/jiocinema-announces-new-ad-free-premium-plan-for-rs-29-a-month-will-ipl-continue-to-be-available-for-free-details-101714017864779.html\n",
      "ArticleData/110.txt\n",
      "ArticleData/111.txt\n",
      "ArticleData/112.txt\n",
      "ArticleData/113.txt\n",
      "Error 404 https://www.icicidirect.com/research/equity/blog/with-merger-consummated-jio-cinema-viacom18-seeking-to-create-ott-behemoth\n"
     ]
    }
   ],
   "source": [
    "FileNameP=[]#This stores all the name of the processed article stored in the system\n",
    "FileName=[]#This stores all the name of the article stored in the system\n",
    "IntShape=0\n",
    "\n",
    "#used clean and extract the data\n",
    "while (IntShape!=114):\n",
    "    \n",
    "\n",
    "    try:\n",
    "        name = DataExtration(df.iloc[IntShape,0],df.iloc[IntShape,1],file_dict)\n",
    "        print(name)\n",
    "        FileName.append(name)\n",
    "\n",
    "        name=StopWordRemoval(name,df.iloc[IntShape,0])\n",
    "\n",
    "        FileNameP.append(name)\n",
    "        IntShape+=1\n",
    "\n",
    "    except:\n",
    "        print(\"Error 404 \"+df.iloc[IntShape,1])\n",
    "        IntShape+=1\n",
    "\n",
    "#Used to Calculate the rest of the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56568/315326853.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.6565208812244236' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=Pos\n",
      "/tmp/ipykernel_56568/315326853.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.13834818478790112' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=Neg\n",
      "/tmp/ipykernel_56568/315326853.py:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.651897920628797' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=polar\n",
      "/tmp/ipykernel_56568/315326853.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.003472043956385698' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=Sub\n",
      "/tmp/ipykernel_56568/315326853.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '11.45' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=AverageSentence\n",
      "/tmp/ipykernel_56568/315326853.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.7379912663755459' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=PercentageComplex\n",
      "/tmp/ipykernel_56568/315326853.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4.8751965065502185' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=FogIndex\n",
      "/tmp/ipykernel_56568/315326853.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.078947368421052' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=AverWord\n",
      "/tmp/ipykernel_56568/315326853.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.8558951965065502' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=SyllabussWord\n",
      "/tmp/ipykernel_56568/315326853.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<function pronouns at 0x7bd7dd8d3380>' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=pronouns\n",
      "/tmp/ipykernel_56568/315326853.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.078947368421052' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[IntShape,DataFrameInt]=AverWord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 404 https://www.investopedia.com/netflix-looks-to-accelerate-revenue-and-subscriber-growth-for-q4-8546779\n",
      "Error 404 https://www.sciencedirect.com/science/article/pii/S0167268123000793\n",
      "Error 404 https://thenextweb.com/news/how-netflix-shapes-mainstream-culture-explained-by-data\n",
      "Error 404 https://www.investopedia.com/is-amazon-prime-worth-it-5081871\n",
      "Error 404 https://www.wired.com/story/amazon-prime-perks/\n",
      "Error 404 https://www.vox.com/recode/2019/5/3/18511544/amazon-prime-oral-history-jeff-bezos-one-day-shipping\n",
      "Error 404 https://www.inc.com/jason-aten/amazon-may-have-just-quietly-added-its-single-most-important-feature.html\n",
      "Error 404 https://www.thehindu.com/entertainment/movies/jiocinema-announces-price-cuts-for-premium-content-subscription-plans-start-at-rs-29-per-month/article68105217.ece\n",
      "Error 404 https://www.businesstoday.in/technology/news/story/reliance-jio-launches-new-plan-with-netflix-amazon-prime-and-jiocinema-check-price-other-details-429152-2024-05-10\n",
      "Error 404 https://indianexpress.com/article/technology/techook/jiocinema-guide-subscription-cost-content-platforms-8670622/\n",
      "Error 404 https://www.hindustantimes.com/business/jiocinema-announces-new-ad-free-premium-plan-for-rs-29-a-month-will-ipl-continue-to-be-available-for-free-details-101714017864779.html\n",
      "Error 404 https://www.timesnownews.com/technology-science/bad-news-jiocinemas-new-subscription-plan-may-put-an-end-to-ipl-matches-for-free-article-109555777\n",
      "Error 404 https://www.afaqs.com/news/media/jiocinema-has-attracted-a-record-number-of-18-sponsors-and-over-250-advertisers-for-tata-ipl-2024\n",
      "Error 404 https://www.business-standard.com/cricket/ipl/jiocinema-sees-51-increase-in-first-day-viewership-figures-of-ipl-2024-124032300721_1.html\n",
      "Error 404 https://www.forbesindia.com/article/storyboard18/big-surge-tata-ipl-2023-on-jiocinema-gets-recordbreaking-1300-croreplus-video-views-in-first-five-weeks/84883/1\n",
      "Error 404 https://www.icicidirect.com/research/equity/blog/with-merger-consummated-jio-cinema-viacom18-seeking-to-create-ott-behemoth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df[[\"POSITIVE SCORE\",\"NEGATIVE SCORE\",\"POLARITY SCORE\",\"SUBJECTIVITY SCORE\",\"AVG SENTENCE LENGTH\",\"PERCENTAGE OF COMPLEX WORDS\",\"FOG INDEX\",\"AVG NUMBER OF WORDS PER SENTENCE\",\"COMPLEX WORD COUNT\",\"WORD COUNT\",\"SYLLABLE PER WORD\",\"PERSONAL PRONOUNS\",\"AVG WORD LENGTH\"]]=0\n",
    "IntShape=0\n",
    "DataFrameInt=2\n",
    "Polarity_scores=[]#Used to store the postive negative and neutral score\n",
    "# TotalWordsArr=[]\n",
    "# ComplexwordArr=[]\n",
    "# NoSyllabusArr=[]\n",
    "# SyllabussWordArr=[]\n",
    "# PercentageComplexArr=[]\n",
    "# polarArr=[]\n",
    "# SubArr=[]\n",
    "# pronounsArr=[]\n",
    "# AverWordArr=[]\n",
    "# SentenceLengthArr=[]\n",
    "# AverageSentenceArr=[]\n",
    "# FogIndexArr=[]\n",
    "while (IntShape!=114):\n",
    "        \n",
    "\n",
    "    try:\n",
    "        DataFrameInt=2\n",
    "\n",
    "        #Used to store the postive negative and neutral score\n",
    "        Neg,Neu,Pos=ScoreCalculator(FileNameP[IntShape])\n",
    "\n",
    "        #Stores the total number of words, complex words amd syllabus \n",
    "        TotalWords,Complexword,NoSyllabus=CountWords(FileNameP[IntShape])\n",
    "\n",
    "        CharCount=0\n",
    "        #SYllabus per word\n",
    "        SyllabussWord=(NoSyllabus/TotalWords)\n",
    "\n",
    "        #Complex word percentage\n",
    "        PercentageComplex=(Complexword/TotalWords) \n",
    "        #Polarity Score and Subjectivity Score\n",
    "        polar,Sub=PolarityCal(TotalWords,Neg,Pos)\n",
    "\n",
    "        #  #Number of Pronouns\n",
    "        pronoun=pronouns(FileName[IntShape])\n",
    "\n",
    "        #Average word length\n",
    "        AverWord=WordLen(FileName[IntShape])\n",
    "        # print(AverWord)\n",
    "        # print(TotalWords)\n",
    "        # print(SentenceLength)\n",
    "\n",
    "        #Total number of Sentences\n",
    "        SentenceLength=Sentence(FileName[IntShape])\n",
    "\n",
    "        #Average lenght of the senetence\n",
    "        AverageSentence=TotalWords/SentenceLength\n",
    "\n",
    "        #Fog Index\n",
    "        FogIndex=(0.4*(AverageSentence+PercentageComplex))\n",
    "\n",
    "\n",
    "        df.iloc[IntShape,DataFrameInt]=Pos\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=Neg\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=polar\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=Sub\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=AverageSentence\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=PercentageComplex\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=FogIndex\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=AverWord\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=Complexword\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=TotalWords\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=SyllabussWord\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=\"Unknown\"\n",
    "        DataFrameInt+=1\n",
    "        df.iloc[IntShape,DataFrameInt]=AverWord\n",
    "        DataFrameInt+=1    \n",
    "\n",
    "        IntShape+=1\n",
    "    \n",
    "    except:\n",
    "        print(\"Error 404 file not found \"+df.iloc[IntShape,1])\n",
    "        IntShape+=1\n",
    "\n",
    "\n",
    "df.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
